{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff917b0",
   "metadata": {
    "id": "2ff917b0"
   },
   "source": [
    "# HW3: Dataset Overview and Use Case Examples\n",
    "## EDS 220, Fall 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3205c4c",
   "metadata": {
    "id": "c3205c4c"
   },
   "source": [
    "## Informing Oil Spill Impacts with High Frequency Radar Surface Current Data\n",
    "### U.S. West Coast, 6km, hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d4f0d",
   "metadata": {
    "id": "466d4f0d"
   },
   "source": [
    "### Authors\n",
    "- Elmera Azadpour, UC Santa Barbara, 2nd Year MESM\n",
    "- Ian Brunjes, UC Santa Barbara, 2nd Year MESM\n",
    "- Phillip Puettmann, UC Santa Barbara, 2nd Year Information Systems (Germany)\n",
    "- Quin Smith, UC Santa Barbara, 2nd Year MESM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50bac4e",
   "metadata": {
    "id": "b50bac4e"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "[1. Purpose](#purpose)\n",
    "\n",
    "[2. Dataset Description](#overview)\n",
    "\n",
    "[3. Data I/O](#io)\n",
    "\n",
    "[4. Metadata Display and Basic Visualization](#display)\n",
    "\n",
    "[5. Use Case Examples](#usecases)\n",
    "\n",
    "[6. Create Binder Environment](#binder)\n",
    "\n",
    "[7. References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617bf770",
   "metadata": {
    "id": "617bf770"
   },
   "source": [
    "<a id='purpose'></a> \n",
    "### Notebook Purpose\n",
    "\n",
    "The purpose of this notebook is to provide an introduction to using high frequency radar data from the Integrated Ocean Observing System network to derive surface current velocity and direction in the Huntington Beach area during the recent oil spill.\n",
    "\n",
    "HF radar data are land-based radar systems that use radio waves to measure the speed and direction of ocean surface currents in near real-time. These radar systems can measure the top 1-2 meter of water column from a range of 200 km away from shore. There is a network of 62 HF radars that contribute to the regional data for the California coast, with resolutions ranging from 500 m to 6 km depending on radar frequency. Specifically, this notebook will explore 6 km resolution (hourly) high frequency (HF) radar data of surface currents from the Scripps Institute of Oceanography, UCSD for analysis of the 2021 oil spill off the coast of Huntington Beach, CA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d835e39",
   "metadata": {
    "id": "9d835e39"
   },
   "source": [
    "<a id='overview'></a> \n",
    "### Dataset Description\n",
    "\n",
    "This dataset was created by the Coastal Observing Research and Development Center at Scripps Institution of Oceanography, UCSD. The [ HF radar Thredds data server](https://hfrnet-tds.ucsd.edu/thredds/catalog.html) contains real-time velocity (RTV) measurements across the Gulf of Alaska, US East and Gulf Coast, Hawai'i, Puerto Rico and Virgin Islands, and US West Coast. The server contains data across hourly, 25hr average, monthly average and annual average RTV. For our purposes, we will download US West Coast 6 km resolution, hourly data in netCDF format. To retrieve this data, we have pulled from the Thredds server using OPeNDAP and xarray.\n",
    "\n",
    "Upon early data exploration, we noticed the 6 km hourly data does not have complete coverage across the time series and contains spatial incompleteness (NaNs). However, the dataset contains metadata with information regarding data format (datetime64) and geospatial coordinate information (WGS84, Degrees N & E). For our analysis, we have focused on the time frame October 4th, 2021 - October 7th, 2021 to analyze RTV measurements from the recent oil spill off the coast of Huntington Beach, CA.\n",
    "\n",
    "Later on, we want to add the actual oil blob movements over time to the plot. We are retrieving this data from a different data source. The data is available from the [Environmental Response Management Application (ERMA)](https://erma.noaa.gov/southwest), which is a web-based Geographic Information System (GIS) tool that assists in dealing with incidents that may adversely impact the environment. ERMA is a project by the NOAA Office of Response and Restauration. Within ERMA, multiple reports are accessible. We want to focus on the NESDIS Marine Pollution Surveillance Reports, which cover data for multiple critical events such as the Huntington Beach spill earlier this year. The data decribes the suspected oil locations and coverages. These results are compiled from satellite data provided by the Copernicus Sentinel mission. Data are either available as images with complete descriptions and annotations, as a layer for an interactive map or available for download. You can see an example of the first one below. However, the data is only available for quite irregular points in time the oil spill took place. This makes it hard to have a stable and ongoing analysis of the movement of the oil.\n",
    "For further processing in our project, we chose to download the data from the website, extracted the relevant shapefiles and consolidated them to one single set of files (*.shp, *.shx , *.cpg, *.prj and *.dbf file) to the \\\"shp\\\" subfolder.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"https://prod-erma-api.orr.noaa.gov/api/v1/data_layer_file/12964/download/\" width=\"800\"/>\n",
    "<br>\n",
    "Fig. 1: Example Sentinel Satellite Imagery with suspected oil annotations\n",
    "<br>\n",
    "Source: https://prod-erma-api.orr.noaa.gov/api/v1/data_layer_file/12964/download/\n",
    "<center>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Apart from the aforementioned data gaps within the spatial and temporal dimensions, we face some minor variations in data quality due to the physical circumstances at the time of measurement: \n",
    "The HF radar transmissions for example are subject to interferences. As a matter of fact, the added noise in busy wavelength channels affect data accuracy and also the current operation range of the radars. You can check on these data (and much more) at the public sites' diagnostics pages (e.g. https://hfrnet.ucsd.edu/diagnostics/?p=sta&t=0&sta=COP1 for Coal Oil Point). This gives you some indicators of operational data quality.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"https://github.com/fullbeats/EDS220-SeaSurfaceCurrents/blob/main/img/HFsitecoverage.png?raw=1\" width=\"800\"/>\n",
    "<br>\n",
    "Fig. 2: HF site spatial coverage for Coal Oil Point\n",
    "<br>\n",
    "Source: https://hfrnet.ucsd.edu/diagnostics/?p=sta&t=0&sta=COP1\n",
    "<center>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"https://github.com/fullbeats/EDS220-SeaSurfaceCurrents/blob/main/img/HFsiterange.png?raw=1\" width=\"800\"/>\n",
    "<br>\n",
    "Fig. 3: HF range over time for Coal Oil Point\n",
    "<br>\n",
    "Source: https://hfrnet.ucsd.edu/diagnostics/?p=sta&t=0&sta=COP1\n",
    "<center>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Looking at the data quality of the suspected oil coverages compiled from the Sentinel satellite images we assume that the annotations and actual shapes of the suspected oil were drawn by satellite imagery analysts. They report a confidence level of \"medium-high\" for that data, which is the second highest value on a four-level scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19093f06",
   "metadata": {
    "id": "19093f06"
   },
   "source": [
    "<a id='io'></a> \n",
    "### Dataset Input/Output \n",
    "\n",
    "Here, we provide code to read in the data.\n",
    "\n",
    "1) Import necessary packages\n",
    "\n",
    "2) Set the data import parameters and import the data!:\n",
    "- set variable names to store imported data, 'lazy' import using `xr.open_dataset()`\n",
    "- filter over temporal range and region of interest\n",
    "- store time-series of the data to be used later\n",
    "- store size of array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53461b90",
   "metadata": {
    "id": "53461b90"
   },
   "outputs": [],
   "source": [
    "#load packages\n",
    "import contextily as ctx\n",
    "import geopandas as gpd\n",
    "import imageio as io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d201171",
   "metadata": {
    "id": "0d201171"
   },
   "outputs": [],
   "source": [
    "# Using thredds server url and xarray, read in the dataset\n",
    "url = 'http://hfrnet-tds.ucsd.edu/thredds/dodsC/HFR/USWC/6km/hourly/RTV/HFRADAR_US_West_Coast_6km_Resolution_Hourly_RTV_best.ncd'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61012583",
   "metadata": {
    "id": "61012583"
   },
   "outputs": [],
   "source": [
    "# Set ROI variables\n",
    "# ROI bounding box: -119.413147,32.858825,-117.215881,34.064037\n",
    "x1, y1, x2, y2 = (-119.413147,32.858825,-117.215881,34.064037)\n",
    "# Start/End date\n",
    "start_dt, end_dt = (\"2021-10-04\", \"2021-10-07\")\n",
    "# CRS\n",
    "crs_4326 = 'EPSG:4326'\n",
    "\n",
    "# Slice data to desired geographic and temporal coverage\n",
    "\n",
    "\n",
    "# Store times in array for later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65c3642",
   "metadata": {
    "id": "a65c3642",
    "outputId": "518cd71e-072e-4a6e-cef1-600ab64a4cfc"
   },
   "outputs": [],
   "source": [
    "# Get dimensions of array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73638e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove axis with length of 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2213a505",
   "metadata": {
    "id": "2213a505"
   },
   "source": [
    "<a id='display'></a> \n",
    "### Metadata Display and Basic Visualization\n",
    "\n",
    "Next, let's look at the variables and metadata for our HF data. The netCDF data is stored as an xarray object, which we can read by calling the object's variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f9330",
   "metadata": {
    "id": "a04f9330",
    "outputId": "67d71d12-6722-4dda-d806-77c3b8d395d7"
   },
   "outputs": [],
   "source": [
    "# Peak at xarray metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9afdb-fca4-423c-8a55-5a93b9c62756",
   "metadata": {
    "id": "19d9afdb-fca4-423c-8a55-5a93b9c62756"
   },
   "source": [
    "The data contains 14 variables:\n",
    "- time_bnds\n",
    "- depth_bnds\n",
    "- wgs84\n",
    "- processing_parameters\n",
    "- radial_metadata\n",
    "- depth\n",
    "- time_offset\n",
    "- u\n",
    "- v\n",
    "- dopx\n",
    "- dopy\n",
    "- hdop\n",
    "- number_of_sites\n",
    "- number_of_radials\n",
    "\n",
    "For our analysis, we are most interested in the vector components (u and v), which will be used to derive velocity and direction of sea surface currents. However, the other variables are also important and worthwhile to explore at a later date. For example, dopx, dopy, and hdop are all measures of \"dilution of precision\", basically the uncertainty associated with the vector component values. Here is a list of some of the most important variables in the dataset, as specified on the [website](https://hfrnet-tds.ucsd.edu/thredds/catalog/HFR/USWC/6km/hourly/RTV/catalog.html?dataset=HFR/USWC/6km/hourly/RTV/HFRADAR_US_West_Coast_6km_Resolution_Hourly_RTV_best.ncd):\n",
    "\n",
    "- dopx = longitudinal dilution of precision\n",
    "- dopy = latitudinal dilution of precision\n",
    "- hdop = horizontal dilution of precision\n",
    "- number_of_radials (count) = number of contributing radials\n",
    "- number_of_sites (count) = number of contributing radars\n",
    "- u (m s-1) = surface eastward sea water velocity\n",
    "- v (m s-1) = surface northward sea water velocity\n",
    "\n",
    "Additionally, metadata is stored for the data under the 'Attributes' tab of the output.  These include:\n",
    "\n",
    "- Conventions\n",
    "- id\n",
    "- date_created\n",
    "- source\n",
    "- program\n",
    "- title\n",
    "- summary\n",
    "- instrument\n",
    "- keywords\n",
    "- geospatial_lat_min\n",
    "- geospatial_lat_max\n",
    "- geospatial_lon_min\n",
    "- geospatial_lon_max\n",
    "- processing_level\n",
    "- history\n",
    "- references\n",
    "- institution\n",
    "- creator_type\n",
    "- creator_name\n",
    "- creator_email\n",
    "- creator_url\n",
    "- naming_authority\n",
    "- standard_name_vocabulary\n",
    "- keywords_vocabulary\n",
    "- instrument_vocabulary\n",
    "- format_version\n",
    "- product_version \n",
    "- _CoordSysBuilder\n",
    "- cdm_data_type\n",
    "- featureType\n",
    "- location\n",
    "\n",
    "These metadata very helpful in describing the dataset and attributing credit to the various creators and organizations involved. They can be viewed and explored in the above output. But now let's create a preliminary visualization over an arbitrary coordinate to check for obvious data gaps. We'll use lucky number 13 to index both latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8950bf",
   "metadata": {
    "id": "ee8950bf",
    "outputId": "637e39fc-74e6-4fda-b012-87ab3979a264"
   },
   "outputs": [],
   "source": [
    "# Plot u & v for a valid coordinate over timespan to check data gaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa4ac7-9ddb-4b26-806c-fa34f67796a9",
   "metadata": {
    "id": "e7fa4ac7-9ddb-4b26-806c-fa34f67796a9"
   },
   "source": [
    "Our preliminary glance at the data looks pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bd3b7",
   "metadata": {},
   "source": [
    "The final step of our data prep is to coerce the data into more easily manipulated object types, and clean it up- it inherently has a lot of NaN values, since many of the coordinate pairings within the bounding box fall on land and other areas where HFR surface current readings are not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast our 3 dimensional xarray to dataframe\n",
    "\n",
    "\n",
    "# Remove rows with NaN\n",
    "\n",
    "\n",
    "# Build a geodataframe using lat lon for geometries and our desired CRS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b44f81",
   "metadata": {
    "id": "76b44f81"
   },
   "source": [
    "<a id='usecases'></a> \n",
    "### Use Case Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7482c479",
   "metadata": {
    "id": "7482c479"
   },
   "source": [
    "#### Visualizing Surface Currents over Oil Spill Satellite Imagery\n",
    "\n",
    "For our analysis, we will look at the sea surface currents near Huntington Beach during the 2021 oil spill. We want to determine if patterns in how the \"blob\" behaved during this period can be correlated with observed sea surface currents. It is crucial for agencies responding to oil spill emergencies to be able to predict how oil will move in real time. Real time data acquistion is important to ensure that resources are spent in a targeted and efficient manner, and that reliable information can be shared with the public to reduce the threat to life and livelihood.\n",
    "\n",
    "The analysis will demonstrate how to plot \"quivers\" or directional vectors using matplotlib, manipulation of spatial data via GeoDataFrames, and how to create animated plots and gifs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8874996",
   "metadata": {
    "id": "bb951810",
    "outputId": "d984f36b-ee76-4215-e602-b36f38017fac"
   },
   "source": [
    "Using vector math, we want to find the magnitude of each data point. These values will be used to plot the surface currents.\n",
    "\n",
    "Given the eastward velocity u, and northward velocity v, we can find the magnitude:\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"https://github.com/fullbeats/EDS220-SeaSurfaceCurrents/blob/main/img/vectormagnitude.png?raw=1\" width=\"800\"/>\n",
    "<br>\n",
    "Fig. 4: Finding the magnitude of a vector.\n",
    "<br>\n",
    "Source: https://math.lakschool.com/en/themen/vektor/images/vektor_betrag.png\n",
    "<center>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411858f7",
   "metadata": {
    "id": "411858f7"
   },
   "outputs": [],
   "source": [
    "# Create a new column in df with the magnitude of our vectors\n",
    "\n",
    "\n",
    "# To normalize the vector length, we can use our calculated magnitude\n",
    "# Create normalized vectors for plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc6021",
   "metadata": {},
   "source": [
    "By default the magnitude of vectors is represented by their length while plotting. Let's see what that looks like, using the built in quivers functionality of matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af906532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an arbitrary time index to plot\n",
    "\n",
    "\n",
    "# Subset our data to points at the chosen time\n",
    "\n",
    "\n",
    "# Set up plot\n",
    "\n",
    "\n",
    "# Build quivers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82013e45",
   "metadata": {},
   "source": [
    "For our visualization, the different length vectors can be hard to read. Let's instead standardize the vector length, and represent magnitude using a color scale instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77acf99",
   "metadata": {
    "id": "f77acf99"
   },
   "outputs": [],
   "source": [
    "# To build a color gradient representing magnitude, we will first\n",
    "# look at the distribution of magnitude values to determine\n",
    "# what range makes sense for the scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a color scale that aligns with range of magnitude values\n",
    "\n",
    "\n",
    "# Set color palette\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53677f",
   "metadata": {
    "id": "ca53677f",
    "outputId": "3640dac4-e692-44b0-fda3-2f1808f2f1f9"
   },
   "outputs": [],
   "source": [
    "# Build a plot, now providing a color parameter to the quivers\n",
    "\n",
    "\n",
    "# Choose another time index to plot\n",
    "\n",
    "\n",
    "# Subset our data to points at the chosen time\n",
    "\n",
    "\n",
    "# Build quivers\n",
    "\n",
    "\n",
    "# Add basemap\n",
    "\n",
    "\n",
    "# Additional plot formatting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d963f",
   "metadata": {},
   "source": [
    "We're now able to get a nice representation of our surface current vectors.. at a single timestamp.\n",
    "\n",
    "What we would like to visualize is the change in these currents across our timespan. To do so, we will utilize matplotlibs animated plot functionality, FuncAnimation. Each frame of the animation will be a step through time, which for our data is in one hour increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703ea77",
   "metadata": {
    "id": "1703ea77",
    "outputId": "1e541757-8603-45b3-ae94-f70ecc78610c"
   },
   "outputs": [],
   "source": [
    "# inline plots for jupyter notebook don't support animation, need to switch plot output to use notebook backend\n",
    "%matplotlib notebook\n",
    "\n",
    "# Provision the initial plot for the animation to start from at time 0.\n",
    "\n",
    "\n",
    "# We will want to start at time index 0\n",
    "\n",
    "\n",
    "# Subset our data to points at the chosen time\n",
    "\n",
    "\n",
    "# Build quivers\n",
    "\n",
    "\n",
    "# Add basemap\n",
    "\n",
    "# Additional plot formatting\n",
    "\n",
    "# Pythons FuncAnimation will call a function at each new frame, within which we can make updates to our plot\n",
    "# We define the function here.\n",
    "def updatePlot(frame):\n",
    "    return\n",
    "    # Subset our data to points at the chosen time\n",
    "    \n",
    "    \n",
    "    # Since this function updates the existing plot, we need to clear the existing quivers with each new frame\n",
    "\n",
    "    \n",
    "    # Add the new quivers from our current timestamps subset of data\n",
    "    \n",
    "    \n",
    "    # Update the title with the current timestamp\n",
    "    \n",
    "    \n",
    "    # Add back the other formatting lost when calling ax.clear()\n",
    "    \n",
    "\n",
    "# Now we can invoke the animation function\n",
    "# The number of frames = number of indexes in our timespan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4f72d8",
   "metadata": {},
   "source": [
    "With the surface currents visualized, we now would like to add in an extra layer: the oil spill!\n",
    "\n",
    "Satellite imagery of the ocean surface, taken over the few days of the oil spill, reveal the extent and spread of oil through the ocean. The NESDIS Marine Pollution Surveillance Reports provide shapefiles of suspected oil that was present in the satellite images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in oil shape files and format\n",
    "\n",
    "# Project to the same CRS as our other data\n",
    "\n",
    "# Convert timestamp to datetime object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c8267",
   "metadata": {},
   "source": [
    "We want to enhance our visualization with the suspected oil blobs present on the ocean surface, with the most updated imagery being added as we step through time.\n",
    "\n",
    "While the we want the outcome to be similar as above, an animated plot stepping through each hour, we will take a different approach to building it- this time using imageio to generate a .gif file that we could email to our moms to show how cool our grad program is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# # Rather than a plot that continuously updates as it iterates through each frame\n",
    "# # we will store each individual frame as an image to combine later into a gif\n",
    "# images = []\n",
    "\n",
    "# # Build the plot for each frame of data in our time series\n",
    "# for frame in range(0,times.size):\n",
    "#     # First clear out any existing plot objects\n",
    "#     plt.cla()\n",
    "    \n",
    "#     # Then build the individual plot for this timestamp\n",
    "#     fig, ax = plt.subplots(figsize=(15,12))\n",
    "\n",
    "#     # Subset our surface current data to points at the chosen time\n",
    "#     geo_df_t = geo_df[geo_df['time'] == times[frame]]\n",
    "    \n",
    "#     # Also subset and plot the oil shapefiles based on if they should be included for the current timestamp\n",
    "#     current_oil = oil_shapes[oil_shapes['DATETIME'] < str(times[frame])]\n",
    "    \n",
    "#     if current_oil.size > 0:\n",
    "#         current_oil.plot(ax = ax, color = \"black\")\n",
    "\n",
    "#     # Build quivers\n",
    "#     ax.quiver(geo_df_t['geometry'].x, # x coordinate of vector location\n",
    "#               geo_df_t['geometry'].y, # y coordinate of vector location\n",
    "#               geo_df_t['u_norm'],     # normalized u value\n",
    "#               geo_df_t['v_norm'],     # normalized v value\n",
    "#               color=colormap(norm(geo_df_t['magnitude'])) # mapping of magnitudes to color values\n",
    "#              )\n",
    "\n",
    "#     # Add basemap\n",
    "#     ctx.add_basemap(ax, crs=geo_df_t.crs.to_string(), source=ctx.providers.Stamen.Terrain)\n",
    "\n",
    "#     # Additional plot formatting\n",
    "#     ax.set_axis_off()\n",
    "#     ax.set_title('HFR Surface Currents: ' + str(times[frame]))\n",
    "    \n",
    "#     # Once the plot is finished, save it to a file\n",
    "#     filename = './images/frame_'+str(frame)+'.png'\n",
    "#     plt.savefig(filename)\n",
    "#     plt.close()\n",
    "    \n",
    "#     # Store the image file into our array of images, which will contain all of our frames\n",
    "#     images.append(io.imread(filename))\n",
    "\n",
    "# # Create a single gif file that consolidates all images in our array\n",
    "# io.mimsave('./images/oil_spill.gif', images, duration = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca9fa4",
   "metadata": {},
   "source": [
    "The results of this exercise provide an important narrative for events such as the Huntington Beach 2021 oil spill. With realtime hourly collection of these surface current data, it becomes clear how such tools can be actively used to plan oil spill response and recovery.\n",
    "\n",
    "Being just one of many factors that inform oil flow, this analysis could be extended to include other oceanographic and atmospheric variables, and be shifted into a more formal modeling approach that could be utilized for making predictions on what areas will be affected by an oil spill, before it actually reaches them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1254e9b9",
   "metadata": {
    "id": "1254e9b9"
   },
   "source": [
    "<a id='binder'></a> \n",
    "### Create Binder Environment\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/fullbeats/EDS220-SeaSurfaceCurrents/HEAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7232f465",
   "metadata": {
    "id": "7232f465"
   },
   "source": [
    "<a id='references'></a> \n",
    "### References\n",
    "\n",
    "List relevant references. Here are some additional resources on creating professional, shareable notebooks you may find useful:\n",
    "\n",
    "1. Vector math and trigonometry resource: https://math.libretexts.org/Bookshelves/Precalculus/Precalculus_(OpenStax)/08%3A_Further_Applications_of_Trigonometry/8.08%3A_Vectors\n",
    "2. NESDIS Marine Pollution Data Source for Suspected Oil from Satellite Imagery: https://erma.noaa.gov/southwest#/layers=1+48526+48525+48506+48569+48575+48462+48452+48423&x=-118.12634&y=33.47098&z=9.6&panel=layer\n",
    "3. Background on HFR surface current data for the U.S. West Coast: https://sccoos.org/high-frequency-radar/\n",
    "4. Thredds server with HF Radar Measurements: https://hfrnet-tds.ucsd.edu/thredds/catalog.html\n",
    "5. Integrated Ocean Observing System, About HF Radar: https://ioos.noaa.gov/project/hf-radar/\n",
    "6. Coastal HF radars in the Mid-Atlantic Bight: http://www.codar.com/images/about/2012_Kohut_OceanDynamics.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87fd69",
   "metadata": {
    "id": "af87fd69"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW3_rs_crew.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "bae972f585f953ba134a2ac6d01037e2ffbc01ce30a2b68a8238fb3e0399e8e8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
